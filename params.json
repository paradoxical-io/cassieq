{"name":"Cassieq","tagline":"A distributed queue built off cassandra","body":"io.paradoxical.cassieq  \r\n=====\r\n\r\n![Build status](https://travis-ci.org/paradoxical-io/cassieq.svg?branch=master)\r\n\r\nCassieQ is a distributed queue built on cassandra. Yes, we know, queues on cassandra are an anti-pattern,\r\nbut only when you use secondary indexes, and lots of polls and scans which CassieQ _doesn't_ do.\r\n\r\nCassieQ provides:\r\n\r\n- at least once delivery\r\n- invisiblity of messages\r\n- simple API of get/ack\r\n- highly scaleable\r\n\r\n## To run\r\n\r\n```\r\ndocker run -it \\\r\n    -e KEYSPACE=\"\" \\\r\n    -e CONTACT_POINTS=\"\" \\\r\n    -e USERNAME=\"\" \\\r\n    -e PASSWORD=\"\" \\\r\n    paradoxical/cassieq\r\n```\r\n\r\nIf you don't want to use environment variables, you can mount a volume to `/data/conf` and provide your own\r\nyaml\r\n\r\n## Bootstrapping required tables\r\n\r\n```\r\ndocker run -it \\\r\n    -e KEYSPACE=\"\" \\\r\n        -e CONTACT_POINTS=\"\" \\\r\n        -e USERNAME=\"\" \\\r\n        -e PASSWORD=\"\" \\\r\n    paradoxical/cassieq bootstrap\r\n```\r\n\r\nThis will build out the required tables in your keyspace. \r\n\r\nIf your user has permissions to create a keyspace you can run\r\n\r\n```\r\ndocker run -it \\\r\n    -e KEYSPACE=\"\" \\\r\n        -e CONTACT_POINTS=\"\" \\\r\n        -e USERNAME=\"\" \\\r\n        -e PASSWORD=\"\" \\\r\n    paradoxical/cassieq bootstrap -createKeyspace\r\n```\r\n\r\n## Available env vars\r\n\r\nNested properties are only enabled if the parent is enabled\r\n\r\n- CLUSTER_NAME\r\n- KEYSPACE\r\n- CONTACT_POINTS\r\n- AUTH_PROVIDER - defaults to \"plainText\"\r\n- USERNAME\r\n- PASSWORD\r\n- CONSISTENCY_LEVEL - defaults to LOCAL_QUOURUM\r\n- CASSANDRA_PORT - defaults to 9042\r\n- USE_SSL - \"true\" or \"false\"\r\n  - SSL_PORT - defaults to 9043\r\n  - DATA_CENTER - uses this data center as a load balancing policy\r\n- USE_METRICS_GRAPHITE - \"true\" or \"false\"\r\n  - GRAPHITE_URL \r\n  - GRAPHITE_PREFIX \r\n- LOGSTASH_CUSTOM_APP_NAME\r\n\r\n## Why make a queue on cassandra?\r\n\r\nCassandra is a great datastore that is massively horizontally scaleable. It also exists at a lot of organizations\r\nalready.  Being able to use a horizontally scaleable data store means you can ingest incredible amounts of messages.\r\n \r\nAlso by providing a simple docker container that houses an REST web api, you can scale out the queue by tossing \r\nmore docker instances at your cassandra queue.\r\n\r\nCassieQ is fully encapsulated and only needs to know your cassandra information. Future work will include \r\npassing the cassandra cluster credentials and connection information via docker env vars and auto populating\r\nthe tracking tables for queues.\r\n\r\n## How does CassieQ work?\r\n\r\nMessages are put into a queue and can be read from the queue with a visiblity timeout. This means\r\nthat if the message isn't acked within the visiblity timeout it becomes visible again.  Most other queue systems\r\ndeal with this by detecting severed connections but since angenlahir is http based and connectionless we can't rely on that.\r\n\r\n\r\nCassieQ works with 3 pointers into a queue.\r\n\r\n- A reader bucket pointer\r\n- A repair bucket pointer\r\n- An invisiblity pointer\r\n\r\nThese three pointers will be discussed in each section\r\n\r\nIn order to scale and efficiently act as a queue we need to leverage cassandra partitioning capabilities.\r\nQueues are actually messages bucketized into a fixed size group called a bucket.   \r\nEach message is assigned a monotonically increasing id that maps itself into a bucket. \r\n\r\nFor example, if the bucket is size 20 and you have id 21, that maps into bucket 1 (21/20).  \r\n\r\nMessages are always put into the bucket they correlate to, regardless if previous buckets are full.\r\n\r\nThe reader has a pointer to its active bucket (the reader buket pointer) and scans the bucket for unacked visible messages.  If the bucket is full\r\nit tombstones the bucket indicating that the bucket is closed for processing.  If the bucket is NOT full, but all messages\r\nin the bucket are consumed (or being processed) AND the monotonic pointer has already advanced to the next bucket,t he current \r\nbucket is also tombstoned. This means no more messages will ever show up in the current bucket... sort of\r\n\r\n### Repairing delayed writes\r\n\r\nThere is a condition that you can have a delayed write. For example, assume you generate monotonic ids in this sequence:\r\n\r\n```\r\nId 19\r\nId 20\r\nWrite 20\r\nWrite 19\r\n```\r\n\r\nIn this scenario id 20 advances the monotonic bucket to bucket 1 (given buckets are size 20).  That means the reader tombstones\r\nbucket 0. But what happenes to message 19? We don't want to lose it, but as far as the reader is concnered its moved onto bucket 1 and off of bucket 0.\r\n\r\nThis is where the concept of a repair worker comes into play. The repair worker's job is to slowly follow the reader and wait for tombstoned buckets. It \r\nhas its own pointer (the repair bucket pointer)\r\n\r\nIf a bucket is tombstoned the repair worker will wait for a configured timeout for _out of order missing messages_ to appear. This means if a slightly\r\ndelayed write occurs then the repair worker will actually pick it up and then _republish it_ to the last active bucket.\r\n\r\nThis means we don't necessarily guarantee FIFO, however we do guarantee messages will appear.\r\n\r\n### Invisibility\r\n\r\nNow the question comes up as how to deal with invsibility of messages. For this there is a separate pointer tracking \r\nthe last invisible pointer.  When a read comes in, we first check the invsiblity pointer to see if that message is now visible.\r\n\r\nIf it is, we can return it. If not, get the next available message.  \r\n\r\nIf the current invisible pointer is already acked then we need to find the next invisible pointer. This next invisible pointer is the first\r\nnon-acked non-visible message. If there isn't one in the current bucket, the invisibility pointer moves to the next bucket until it finds one \r\nor no messages exist.\r\n\r\n## API\r\n\r\nWe have bundled a java client to talk to a simple rest api. The api supports\r\n\r\n- Queue create\r\n- Put a message\r\n- Get a message\r\n- Ack a message\r\n\r\nGetting a message gives you a pop reciept that encodes the message index AND its version. This means that you can prevent multiple ackers of a message\r\nand do conditional atomic actions based on that message version.\r\n\r\nExecute cassieq local\r\n====\r\n\r\n```\r\n./scripts/run-core.sh\r\n```","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}